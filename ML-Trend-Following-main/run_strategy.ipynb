{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THIS NOTEBOOK IS SEPARATED BY SECTION FOR EACH PART OF THE MODEL ESTIMATION AND BACKTEST. READ EACH SECTION DESCRIPTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell installs all required package in the virtual or global environment such that any user can run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: shap in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from shap) (4.66.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\yanis\\python\\mesprojets\\monenv\\lib\\site-packages (from numba->shap) (0.43.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scikit-learn matplotlib scipy shap seaborn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell installs imports all required packages and functions from other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import Functions\n",
    "import importlib\n",
    "import Functions.class_data_processing as data\n",
    "import Functions.classes_signals as signals\n",
    "import Functions.classes_ml_models as ml_models\n",
    "import Functions.class_descriptive_stats as descriptive_stats\n",
    "import Functions.evaluation_ml_models_utils as evaluation\n",
    "from Functions.other_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "importlib.reload(data)\n",
    "importlib.reload(signals)\n",
    "importlib.reload(Functions)\n",
    "importlib.reload(ml_models)\n",
    "importlib.reload(descriptive_stats)\n",
    "importlib.reload(evaluation)\n",
    "\n",
    "from Functions.class_data_processing import DataReader, SignalProcessor\n",
    "from Functions.classes_signals import Return, MovingAverage, CrossMovingAverage, BollingerBands, MinMaxBreakout\n",
    "from Functions.classes_ml_models import RidgeRegression, MultipleLinearRegression, LassoRegression, RandomForestClassification, KMeansClustering\n",
    "from Functions.class_descriptive_stats import DescriptiveStatistics\n",
    "from Functions.evaluation_ml_models_utils import plot_mean_importance, display_average_r2, compute_classification_metrics, plot_average_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "output_folder = \"Outputs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load all of our datasets and set the dates for out data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset class file paths and sheet names\n",
    "COMMOD_filepath = os.path.join('Data', 'Commodities.xlsx')\n",
    "EQUITY_filepath = os.path.join('Data', 'Equities.xlsx')\n",
    "FX_filepath = os.path.join('Data', 'FX.xlsx')\n",
    "BONDS_filepath = os.path.join('Data', 'Bonds.xlsx')\n",
    "MACRO_filepath = os.path.join('Data', 'macro_data.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSET_CLASSES = ['COMMOD', 'EQUITY', 'FX', 'BONDS']\n",
    "COMMOD_sheet_names = ['Crude Oil', 'Nat Gas', 'Copper', 'Wheat', 'Aluminium', 'Nickel', 'Gold', 'Silver', 'Corn', 'Cocoa', 'Soybean', 'Cattle']\n",
    "EQUITY_sheet_names = [\"SPY\", \"UK\", \"EUROSTOXX\", \"JAPAN\", \"HONK KONG\", \"FRANCE\", \"GERMANY\", \"CANADA\", \"RUSSELL2000\", \"QQQ\", \"EU\", \"TAIWAN\", \"ITALY\", \"SWITZERLAND\", \"SOUTH AFRICA\"]\n",
    "FX_sheet_names = [\"USDJPY\", \"EURUSD\", \"GBPUSD\",\"USDCAD\", \"NZDUSD\", \"USDMXN\", \"EURCHF\", \"NOKSEK\", \"EURGBP\", \"USDAUD\"]\n",
    "BONDS_sheet_names = [\"US GOV\", \"CA GOV\", \"EURO GOV\", \"EM GOV\", \"US IG\", \"EURO IG\", \"CA IG\", \"US HY\", \"EURO HY\"]\n",
    "\n",
    "# Start and end dates for training, validation and testing sets\n",
    "train_start_date = '2001-01-01'\n",
    "train_end_date = '2012-12-31'\n",
    "val_start_date = '2013-01-01'\n",
    "val_end_date = '2014-12-31'\n",
    "test_start_date = '2015-01-01'\n",
    "test_end_date = '2024-08-31'\n",
    "\n",
    "# Initialize dictionaries to store data instances and sheet names\n",
    "asset_class_filepaths = {\n",
    "    'COMMOD': COMMOD_filepath,\n",
    "    'EQUITY': EQUITY_filepath,\n",
    "    'FX': FX_filepath,\n",
    "    'BONDS': BONDS_filepath\n",
    "}\n",
    "\n",
    "asset_class_sheet_names = {\n",
    "    'COMMOD': COMMOD_sheet_names,\n",
    "    'EQUITY': EQUITY_sheet_names,\n",
    "    'FX': FX_sheet_names,\n",
    "    'BONDS': BONDS_sheet_names\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We calculate signals for each asset in each asset class. The signals are calculated in the classes_signals.py file in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store predictions, models and covariance matrices\n",
    "predictions_ridge = {}\n",
    "models_ridge = {}\n",
    "\n",
    "predictions_linreg = {}\n",
    "models_linreg = {}\n",
    "\n",
    "predictions_lasso = {}\n",
    "models_lasso = {}\n",
    "\n",
    "predictions_rf = {}\n",
    "models_rf = {}\n",
    "\n",
    "cov_matrices = {}\n",
    "exp_ret_matrices = {}\n",
    "\n",
    "train_asset_class_returns = {}\n",
    "\n",
    "# Load data and signals for each asset class\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Load data\n",
    "    filepath = asset_class_filepaths[asset_class]\n",
    "    sheet_names = asset_class_sheet_names[asset_class]\n",
    "    \n",
    "    # Create data instance for the current asset class\n",
    "    data_instance = DataReader(filepath)\n",
    "    data_instance.load_data(sheet_names)\n",
    "    data_instance.data.columns = sheet_names\n",
    "    data_instance.data = data_instance.data.groupby(data_instance.data.index).first().sort_index()\n",
    "    \n",
    "    # Store data instance in globals for access later\n",
    "    globals()[f\"{asset_class}_data_instance\"] = data_instance\n",
    "    globals()[f\"{asset_class}_sheet_names\"] = sheet_names\n",
    "\n",
    "    # Initialize SignalProcessor for the current asset class from class\n",
    "    signal_processor = SignalProcessor(data_instance.data)\n",
    "    \n",
    "    # Define the signal classes to run\n",
    "    signal_classes = [Return, MovingAverage, CrossMovingAverage, BollingerBands, MinMaxBreakout]\n",
    "    \n",
    "    # Initialize signals dictionary to store signals for each asset in the asset class\n",
    "    signals_dict = {}\n",
    "\n",
    "    # set the train data\n",
    "    train_data = data_instance.data.loc[train_start_date:train_end_date]\n",
    "    \n",
    "    # Calculate the overall return for the current asset class\n",
    "    equal_weights = np.array([1/len(sheet_names)]*len(sheet_names))\n",
    "    train_data_mth = train_data.resample('M').mean()\n",
    "    returns = train_data.pct_change().dropna()*12\n",
    "    train_asset_class_returns[asset_class] = equal_weights @ returns.T\n",
    "\n",
    "    # Calculate the covariance matrix for the current asset class\n",
    "    cov = PortfolioInputs(train_data)\n",
    "    cov_matrices[asset_class] = cov.calculate_covariance_matrix()\n",
    "\n",
    "    \n",
    "    # Process signals for each asset in the current asset class\n",
    "    for asset in sheet_names:\n",
    "        # Define signal parameters\n",
    "        signal_params = {\n",
    "            'Return': ([22, 65], asset),\n",
    "            'MovingAverage': ([22, 65], asset), \n",
    "            'CrossMovingAverage': ([(22, 65), (65, 260)], asset),\n",
    "            'BollingerBands': ([22], asset),\n",
    "            'MinMaxBreakout': ([65], asset)\n",
    "        }\n",
    "    \n",
    "        asset_signals_df = signal_processor.process_signals(asset, signal_classes, signal_params)\n",
    "        \n",
    "        # Store the DataFrame in the signals dictionary\n",
    "        signals_dict[asset] = asset_signals_df\n",
    "    \n",
    "    globals()[f\"{asset_class}_signals_dict\"] = signals_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We fit our linear models (Ridge, Lasso and OLS regressions) and compute monthly predictions and store them. Only Ridge is used after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMOD - Crude Oil (Ridge): Best alpha: 3000.0, Best R2: -0.044399990031798245\n",
      "COMMOD - Crude Oil (Lasso): Best alpha: 30.303030303030305, Best R2: -0.044635838826559214\n",
      "COMMOD - Nat Gas (Ridge): Best alpha: 181.8181818181818, Best R2: -0.01997020388521469\n",
      "COMMOD - Nat Gas (Lasso): Best alpha: 30.303030303030305, Best R2: -0.021955521191660176\n",
      "COMMOD - Copper (Ridge): Best alpha: 969.6969696969697, Best R2: -0.1563449535757166\n",
      "COMMOD - Copper (Lasso): Best alpha: 30.303030303030305, Best R2: -0.1600088082417407\n",
      "COMMOD - Wheat (Ridge): Best alpha: 3000.0, Best R2: -0.016260457493367665\n",
      "COMMOD - Wheat (Lasso): Best alpha: 30.303030303030305, Best R2: -0.015229282297428837\n",
      "COMMOD - Aluminium (Ridge): Best alpha: 3000.0, Best R2: -0.1483038702796585\n",
      "COMMOD - Aluminium (Lasso): Best alpha: 30.303030303030305, Best R2: -0.14262870214794718\n",
      "COMMOD - Nickel (Ridge): Best alpha: 3000.0, Best R2: -0.1983765696876319\n",
      "COMMOD - Nickel (Lasso): Best alpha: 30.303030303030305, Best R2: -0.19566467313357377\n",
      "COMMOD - Gold (Ridge): Best alpha: 181.8181818181818, Best R2: 0.025178572642379726\n",
      "COMMOD - Gold (Lasso): Best alpha: 30.303030303030305, Best R2: -0.010985190054875592\n",
      "COMMOD - Silver (Ridge): Best alpha: 3000.0, Best R2: -0.04501246794602402\n",
      "COMMOD - Silver (Lasso): Best alpha: 30.303030303030305, Best R2: -0.04506768738152504\n",
      "COMMOD - Corn (Ridge): Best alpha: 3000.0, Best R2: -0.03773017697174845\n",
      "COMMOD - Corn (Lasso): Best alpha: 30.303030303030305, Best R2: -0.037425503251897266\n",
      "COMMOD - Cocoa (Ridge): Best alpha: 30.303030303030305, Best R2: 0.080086618796395\n",
      "COMMOD - Cocoa (Lasso): Best alpha: 30.303030303030305, Best R2: -0.019054642585949865\n",
      "COMMOD - Soybean (Ridge): Best alpha: 121.21212121212122, Best R2: -0.005388172950771231\n",
      "COMMOD - Soybean (Lasso): Best alpha: 30.303030303030305, Best R2: -0.00971059127854974\n",
      "COMMOD - Cattle (Ridge): Best alpha: 30.303030303030305, Best R2: -0.019132454384679788\n",
      "COMMOD - Cattle (Lasso): Best alpha: 30.303030303030305, Best R2: -0.035677999985978114\n",
      "EQUITY - SPY (Ridge): Best alpha: 3000.0, Best R2: -0.35124537577892334\n",
      "EQUITY - SPY (Lasso): Best alpha: 30.303030303030305, Best R2: -0.3514818047727279\n",
      "EQUITY - UK (Ridge): Best alpha: 636.3636363636364, Best R2: -0.3082229349957995\n",
      "EQUITY - UK (Lasso): Best alpha: 30.303030303030305, Best R2: -0.317036767337633\n",
      "EQUITY - EUROSTOXX (Ridge): Best alpha: 272.72727272727275, Best R2: -0.04378544396327788\n",
      "EQUITY - EUROSTOXX (Lasso): Best alpha: 30.303030303030305, Best R2: -0.05158567003261307\n",
      "EQUITY - JAPAN (Ridge): Best alpha: 636.3636363636364, Best R2: -0.24787634560657965\n",
      "EQUITY - JAPAN (Lasso): Best alpha: 30.303030303030305, Best R2: -0.25154902331441675\n",
      "EQUITY - HONK KONG (Ridge): Best alpha: 757.5757575757576, Best R2: -0.19426115651600181\n",
      "EQUITY - HONK KONG (Lasso): Best alpha: 30.303030303030305, Best R2: -0.1995070553554418\n",
      "EQUITY - FRANCE (Ridge): Best alpha: 3000.0, Best R2: -0.3356028592572463\n",
      "EQUITY - FRANCE (Lasso): Best alpha: 30.303030303030305, Best R2: -0.329042036118779\n",
      "EQUITY - GERMANY (Ridge): Best alpha: 515.1515151515151, Best R2: -0.29447892434138634\n",
      "EQUITY - GERMANY (Lasso): Best alpha: 30.303030303030305, Best R2: -0.29568663675432016\n",
      "EQUITY - CANADA (Ridge): Best alpha: 90.9090909090909, Best R2: -0.12806348046994337\n",
      "EQUITY - CANADA (Lasso): Best alpha: 30.303030303030305, Best R2: -0.1566750297121527\n",
      "EQUITY - RUSSELL2000 (Ridge): Best alpha: 969.6969696969697, Best R2: -0.1548244934736256\n",
      "EQUITY - RUSSELL2000 (Lasso): Best alpha: 30.303030303030305, Best R2: -0.15685563757624127\n",
      "EQUITY - QQQ (Ridge): Best alpha: 2000.0, Best R2: -0.23093043930328122\n",
      "EQUITY - QQQ (Lasso): Best alpha: 30.303030303030305, Best R2: -0.2315113753628529\n",
      "EQUITY - EU (Ridge): Best alpha: 121.21212121212122, Best R2: -0.28940158897847357\n",
      "EQUITY - EU (Lasso): Best alpha: 30.303030303030305, Best R2: -0.31014085287431103\n",
      "EQUITY - TAIWAN (Ridge): Best alpha: 30.303030303030305, Best R2: -0.0867925008294161\n",
      "EQUITY - TAIWAN (Lasso): Best alpha: 30.303030303030305, Best R2: -0.11956491820718843\n",
      "EQUITY - ITALY (Ridge): Best alpha: 3000.0, Best R2: -0.21432546792106116\n",
      "EQUITY - ITALY (Lasso): Best alpha: 30.303030303030305, Best R2: -0.21168366785465914\n",
      "EQUITY - SWITZERLAND (Ridge): Best alpha: 181.8181818181818, Best R2: -0.2865164014516047\n",
      "EQUITY - SWITZERLAND (Lasso): Best alpha: 30.303030303030305, Best R2: -0.32048324430324465\n",
      "EQUITY - SOUTH AFRICA (Ridge): Best alpha: 121.21212121212122, Best R2: -0.0137180121744221\n",
      "EQUITY - SOUTH AFRICA (Lasso): Best alpha: 30.303030303030305, Best R2: -0.03603382316736501\n",
      "FX - USDJPY (Ridge): Best alpha: 3000.0, Best R2: -0.06903570665559702\n",
      "FX - USDJPY (Lasso): Best alpha: 30.303030303030305, Best R2: -0.06824645966671512\n",
      "FX - EURUSD (Ridge): Best alpha: 939.3939393939395, Best R2: -0.028648927559488023\n",
      "FX - EURUSD (Lasso): Best alpha: 30.303030303030305, Best R2: -0.02876112605137564\n",
      "FX - GBPUSD (Ridge): Best alpha: 3000.0, Best R2: -0.09049525298528933\n",
      "FX - GBPUSD (Lasso): Best alpha: 30.303030303030305, Best R2: -0.08539927677239789\n",
      "FX - USDCAD (Ridge): Best alpha: 90.9090909090909, Best R2: -0.024994453764425262\n",
      "FX - USDCAD (Lasso): Best alpha: 30.303030303030305, Best R2: -0.02452131516218592\n",
      "FX - NZDUSD (Ridge): Best alpha: 3000.0, Best R2: -0.0956002608911933\n",
      "FX - NZDUSD (Lasso): Best alpha: 30.303030303030305, Best R2: -0.09450840840839118\n",
      "FX - USDMXN (Ridge): Best alpha: 3000.0, Best R2: -0.08681090851943503\n",
      "FX - USDMXN (Lasso): Best alpha: 30.303030303030305, Best R2: -0.08098728804814437\n",
      "FX - EURCHF (Ridge): Best alpha: 212.12121212121212, Best R2: -0.027289933624143538\n",
      "FX - EURCHF (Lasso): Best alpha: 30.303030303030305, Best R2: -0.042794378321479566\n",
      "FX - NOKSEK (Ridge): Best alpha: 3000.0, Best R2: -0.054838868206336835\n",
      "FX - NOKSEK (Lasso): Best alpha: 30.303030303030305, Best R2: -0.05473800857131894\n",
      "FX - EURGBP (Ridge): Best alpha: 636.3636363636364, Best R2: -0.07350637656675119\n",
      "FX - EURGBP (Lasso): Best alpha: 30.303030303030305, Best R2: -0.07740055879377947\n",
      "FX - USDAUD (Ridge): Best alpha: 3000.0, Best R2: -0.0644207432805676\n",
      "FX - USDAUD (Lasso): Best alpha: 30.303030303030305, Best R2: -0.06216162019399283\n",
      "BONDS - US GOV (Ridge): Best alpha: 1787.878787878788, Best R2: -0.04790028728682141\n",
      "BONDS - US GOV (Lasso): Best alpha: 30.303030303030305, Best R2: -0.04875390389021113\n",
      "BONDS - CA GOV (Ridge): Best alpha: 303.03030303030306, Best R2: -0.014507140179810496\n",
      "BONDS - CA GOV (Lasso): Best alpha: 30.303030303030305, Best R2: -0.024486646448798676\n",
      "BONDS - EURO GOV (Ridge): Best alpha: 3000.0, Best R2: -0.09571903660998723\n",
      "BONDS - EURO GOV (Lasso): Best alpha: 30.303030303030305, Best R2: -0.09335299954248821\n",
      "BONDS - EM GOV (Ridge): Best alpha: 3000.0, Best R2: -0.08620420319619396\n",
      "BONDS - EM GOV (Lasso): Best alpha: 30.303030303030305, Best R2: -0.08266789452186592\n",
      "BONDS - US IG (Ridge): Best alpha: 3000.0, Best R2: -0.1320369147785707\n",
      "BONDS - US IG (Lasso): Best alpha: 30.303030303030305, Best R2: -0.1250600674998838\n",
      "BONDS - EURO IG (Ridge): Best alpha: 3000.0, Best R2: -0.2136326906952027\n",
      "BONDS - EURO IG (Lasso): Best alpha: 30.303030303030305, Best R2: -0.21187275178459547\n",
      "BONDS - CA IG (Ridge): Best alpha: 3000.0, Best R2: -0.07696947214141336\n",
      "BONDS - CA IG (Lasso): Best alpha: 30.303030303030305, Best R2: -0.07051244891015758\n",
      "BONDS - US HY (Ridge): Best alpha: 393.93939393939394, Best R2: -0.16802798905191887\n",
      "BONDS - US HY (Lasso): Best alpha: 30.303030303030305, Best R2: -0.1877895245269776\n",
      "BONDS - EURO HY (Ridge): Best alpha: 121.21212121212122, Best R2: -0.341011103679466\n",
      "BONDS - EURO HY (Lasso): Best alpha: 30.303030303030305, Best R2: -0.4251344277226597\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store aggregated feature importances for Ridge Regression\n",
    "aggregated_feature_importances_ridge = {asset_class: [] for asset_class in ASSET_CLASSES}\n",
    "ridge_r2_scores = {asset_class: [] for asset_class in ASSET_CLASSES}\n",
    "\n",
    "# Now process each asset to train models and make predictions\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Initialize predictions and models dictionary for this asset class\n",
    "    predictions_ridge[asset_class] = {}\n",
    "    models_ridge[asset_class] = {}\n",
    "    predictions_lasso[asset_class] = {}\n",
    "    models_lasso[asset_class] = {}\n",
    "    models_linreg[asset_class] = {}\n",
    "    predictions_linreg[asset_class] = {}\n",
    "    \n",
    "    # Access data and signals\n",
    "    data_instance = globals()[f\"{asset_class}_data_instance\"]\n",
    "    signals_dict = globals()[f\"{asset_class}_signals_dict\"]\n",
    "    sheet_names = globals()[f\"{asset_class}_sheet_names\"]\n",
    "    \n",
    "    for asset in sheet_names:\n",
    "        try:\n",
    "            # Prepare training data\n",
    "            train_data = data_instance.data[asset].loc[train_start_date:train_end_date]\n",
    "            train_signals = signals_dict[asset].loc[train_start_date:train_end_date]\n",
    "            \n",
    "            # Ensure data is not empty\n",
    "            if train_data.empty or train_signals.empty:\n",
    "                print(f\"Training data or signals for {asset} in {asset_class} is empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # =====================\n",
    "            # Ridge Regression\n",
    "            # =====================\n",
    "            \n",
    "            # Initialize RidgeRegression model from class\n",
    "            ridge_model = RidgeRegression(train_data, train_signals)\n",
    "            \n",
    "            # Define hyperparameter grid for Ridge Regression (alphas)\n",
    "            ridge_alphas = np.linspace(0.0, 3000, 100)\n",
    "            \n",
    "            # Evaluate Ridge model to find best alpha\n",
    "            best_alpha_ridge, best_r2_ridge = ridge_model.evaluate(n_splits=5, alphas=ridge_alphas)\n",
    "            print(f\"{asset_class} - {asset} (Ridge): Best alpha: {best_alpha_ridge}, Best R2: {best_r2_ridge}\")\n",
    "            \n",
    "            # The fit method is already called inside evaluate()\n",
    "            # Store the Ridge model\n",
    "            models_ridge[asset_class][asset] = ridge_model\n",
    "\n",
    "            # Store the R² score for Ridge\n",
    "            ridge_r2_scores[asset_class].append(best_r2_ridge)\n",
    "\n",
    "            # Collect feature importances from Ridge Regression\n",
    "            feature_importance_df_ridge = ridge_model.get_feature_importances()\n",
    "            aggregated_feature_importances_ridge[asset_class].append(feature_importance_df_ridge['Importance'].values)\n",
    "            \n",
    "            # =====================\n",
    "            # Lasso Regression\n",
    "            # =====================\n",
    "            \n",
    "            # Initialize LassoRegression model\n",
    "            lasso_model = LassoRegression(train_data, train_signals)\n",
    "            \n",
    "            # Define hyperparameter grid for Lasso Regression (alphas)\n",
    "            lasso_alphas = np.linspace(0.0, 3000, 100)\n",
    "            \n",
    "            # Evaluate Lasso model to find best alpha\n",
    "            best_alpha_lasso, best_r2_lasso = lasso_model.evaluate(n_splits=5, alphas=lasso_alphas)\n",
    "            print(f\"{asset_class} - {asset} (Lasso): Best alpha: {best_alpha_lasso}, Best R2: {best_r2_lasso}\")\n",
    "            \n",
    "            # The fit method is already called inside evaluate()\n",
    "            # Store the Lasso model\n",
    "            models_lasso[asset_class][asset] = lasso_model\n",
    "            \n",
    "            # =====================\n",
    "            # Linear Regression\n",
    "            # =====================\n",
    "\n",
    "            model_linreg = MultipleLinearRegression(train_data, train_signals)\n",
    "            model_linreg.fit()\n",
    "            models_linreg[asset_class][asset] = model_linreg\n",
    "\n",
    "                        # Prepare testing data\n",
    "            test_signals_daily = signals_dict[asset].loc[test_start_date:test_end_date]\n",
    "            test_data_daily = data_instance.data[asset].loc[test_start_date:test_end_date]\n",
    "\n",
    "            # Ensure testing data is not empty\n",
    "            if test_data_daily.empty or test_signals_daily.empty:\n",
    "                print(f\"Testing data or signals for {asset} in {asset_class} is empty. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Resample to monthly frequency\n",
    "            test_signals_monthly = test_signals_daily.resample('M').last()\n",
    "            test_data_monthly = test_data_daily.resample('M').last()\n",
    "\n",
    "            # Calculate monthly returns for testing set (target variable)\n",
    "            test_y = test_data_monthly.pct_change().shift(-1).dropna()\n",
    "\n",
    "            # Align signals and target variable\n",
    "            test_X = test_signals_monthly.loc[test_y.index]\n",
    "\n",
    "            # Drop any remaining NaN values\n",
    "            test_X = test_X.dropna()\n",
    "            test_y = test_y.loc[test_X.index]\n",
    "\n",
    "            # Ensure testing features and target are not empty\n",
    "            if test_X.empty or test_y.empty:\n",
    "                print(f\"No overlapping data between testing features and target for {asset} in {asset_class}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # =====================\n",
    "            # Ridge Predictions\n",
    "            # =====================\n",
    "\n",
    "            # Scale testing features using the scaler fitted on training data (Ridge)\n",
    "            test_X_scaled_ridge = ridge_model.scaler.transform(test_X.values)\n",
    "\n",
    "            # Predict on testing set using the trained Ridge model\n",
    "            test_predictions_ridge = ridge_model.model.predict(test_X_scaled_ridge)\n",
    "\n",
    "            # Create a DataFrame to store actual and predicted returns (Ridge)\n",
    "            predictions_df_ridge = pd.DataFrame({\n",
    "                'Actual Returns': test_y.values.flatten(),\n",
    "                'Predicted Returns': test_predictions_ridge\n",
    "            }, index=test_y.index)\n",
    "\n",
    "            # Store Ridge predictions\n",
    "            predictions_ridge[asset_class][asset] = predictions_df_ridge\n",
    "\n",
    "            # =====================\n",
    "            # Linear Regression Predictions\n",
    "            # =====================\n",
    "\n",
    "            # Scale testing features using the scaler fitted on training data (Linear Regression)\n",
    "            test_X_scaled_linreg = model_linreg.scaler.transform(test_X.values)\n",
    "\n",
    "            # Predict on testing set using the trained Linear Regression model\n",
    "            test_predictions_linreg = model_linreg.model.predict(test_X_scaled_linreg)\n",
    "\n",
    "            # Create a DataFrame to store actual and predicted returns (Linear Regression)\n",
    "            predictions_df_linreg = pd.DataFrame({\n",
    "                'Actual Returns': test_y.values.flatten(),\n",
    "                'Predicted Returns': test_predictions_linreg\n",
    "            }, index=test_y.index)\n",
    "\n",
    "            # Store Linear Regression predictions\n",
    "            predictions_linreg[asset_class][asset] = predictions_df_linreg\n",
    "\n",
    "            # =====================\n",
    "            # Lasso Predictions\n",
    "            # =====================\n",
    "\n",
    "            # Scale testing features using the scaler fitted on training data (Lasso)\n",
    "            test_X_scaled_lasso = lasso_model.scaler.transform(test_X.values)\n",
    "\n",
    "            # Predict on testing set using the trained Lasso model\n",
    "            test_predictions_lasso = lasso_model.model.predict(test_X_scaled_lasso)\n",
    "\n",
    "            # Create a DataFrame to store actual and predicted returns (Lasso)\n",
    "            predictions_df_lasso = pd.DataFrame({\n",
    "                'Actual Returns': test_y.values.flatten(),\n",
    "                'Predicted Returns': test_predictions_lasso\n",
    "            }, index=test_y.index)\n",
    "\n",
    "            # Store Lasso predictions\n",
    "            predictions_lasso[asset_class][asset] = predictions_df_lasso\n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"An error occurred for {asset} in {asset_class}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # At this point, 'predictions_ridge' dictionary contains predictions for all assets across all asset classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_ridge = ridge_model.X.columns\n",
    "positions = [2,3]\n",
    "names = []\n",
    "for col_name in feature_names_ridge:\n",
    "    name = remove_words_at_positions(col_name, positions)\n",
    "    names.append(name) \n",
    "feature_names_ridge = names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average feature importance and Out of Sample R2 for Ridge models across all asset classes to evaluate model fit and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Feature Importances for COMMOD (Ridge Regression):\n",
      "                Feature  Mean Importance\n",
      "2        Signal EMA 22D         0.002088\n",
      "6  Signal Bollinger 22D        -0.000121\n",
      "5  Signal MACD 65D 260D        -0.000252\n",
      "0     Signal Return 22D        -0.000447\n",
      "3        Signal EMA 65D        -0.000613\n",
      "7   Signal Breakout 65D        -0.001415\n",
      "1     Signal Return 65D        -0.002223\n",
      "4   Signal MACD 22D 65D        -0.002451\n",
      "Plot saved to: Outputs\\COMMOD_Ridge Regression_importance.png\n",
      "Average R² for Ridge Regression in COMMOD: -0.0488\n",
      "\n",
      "Average Feature Importances for EQUITY (Ridge Regression):\n",
      "                Feature  Mean Importance\n",
      "0     Signal Return 22D         0.002244\n",
      "2        Signal EMA 22D         0.001296\n",
      "3        Signal EMA 65D         0.000394\n",
      "5  Signal MACD 65D 260D         0.000361\n",
      "1     Signal Return 65D         0.000325\n",
      "7   Signal Breakout 65D        -0.001017\n",
      "4   Signal MACD 22D 65D        -0.002097\n",
      "6  Signal Bollinger 22D        -0.002142\n",
      "Plot saved to: Outputs\\EQUITY_Ridge Regression_importance.png\n",
      "Average R² for Ridge Regression in EQUITY: -0.2120\n",
      "\n",
      "Average Feature Importances for FX (Ridge Regression):\n",
      "                Feature  Mean Importance\n",
      "6  Signal Bollinger 22D         0.000147\n",
      "7   Signal Breakout 65D         0.000065\n",
      "3        Signal EMA 65D         0.000050\n",
      "2        Signal EMA 22D         0.000028\n",
      "1     Signal Return 65D        -0.000074\n",
      "5  Signal MACD 65D 260D        -0.000133\n",
      "0     Signal Return 22D        -0.000164\n",
      "4   Signal MACD 22D 65D        -0.000478\n",
      "Plot saved to: Outputs\\FX_Ridge Regression_importance.png\n",
      "Average R² for Ridge Regression in FX: -0.0616\n",
      "\n",
      "Average Feature Importances for BONDS (Ridge Regression):\n",
      "                Feature  Mean Importance\n",
      "4   Signal MACD 22D 65D         0.000660\n",
      "5  Signal MACD 65D 260D         0.000525\n",
      "1     Signal Return 65D         0.000479\n",
      "6  Signal Bollinger 22D         0.000361\n",
      "0     Signal Return 22D         0.000333\n",
      "7   Signal Breakout 65D         0.000153\n",
      "3        Signal EMA 65D         0.000094\n",
      "2        Signal EMA 22D        -0.000055\n",
      "Plot saved to: Outputs\\BONDS_Ridge Regression_importance.png\n",
      "Average R² for Ridge Regression in BONDS: -0.1307\n"
     ]
    }
   ],
   "source": [
    "for asset_class in ASSET_CLASSES:\n",
    "     # Plot feature importances and R2 for Ridge\n",
    "     plot_mean_importance(\n",
    "         asset_class,\n",
    "         aggregated_feature_importances_ridge[asset_class],\n",
    "         feature_names_ridge,\n",
    "         model_name=\"Ridge Regression\"\n",
    "     )\n",
    "     # Display average R2 for Ridge for each asset class\n",
    "     display_average_r2(\n",
    "         asset_class,\n",
    "         ridge_r2_scores[asset_class],\n",
    "         model_name=\"Ridge Regression\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We fit our Random Forest model and compute monthly predictions (probability of up movement) and store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMOD - Crude Oil: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.7347529839576883\n",
      "COMMOD - Nat Gas: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.755398486663344\n",
      "COMMOD - Copper: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7449309367572894\n",
      "COMMOD - Wheat: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Best Negative Log Loss: -0.7185787084357923\n",
      "COMMOD - Aluminium: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.753518561017563\n",
      "COMMOD - Nickel: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.7763134283413438\n",
      "COMMOD - Gold: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.6842428939276408\n",
      "COMMOD - Silver: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, Best Negative Log Loss: -0.7283270683370456\n",
      "COMMOD - Corn: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7529725914130163\n",
      "COMMOD - Cocoa: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.6935775051950805\n",
      "COMMOD - Soybean: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, Best Negative Log Loss: -0.733867288376764\n",
      "COMMOD - Cattle: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7340900849523498\n",
      "EQUITY - SPY: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.8500843120645187\n",
      "EQUITY - UK: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7842385571597081\n",
      "EQUITY - EUROSTOXX: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, Best Negative Log Loss: -0.7539532466564973\n",
      "EQUITY - JAPAN: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7839536137512808\n",
      "EQUITY - HONK KONG: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.8167847686543462\n",
      "EQUITY - FRANCE: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.8881296520064621\n",
      "EQUITY - GERMANY: Best Params: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.820328657689811\n",
      "EQUITY - CANADA: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7415380489562926\n",
      "EQUITY - RUSSELL2000: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7312619227428335\n",
      "EQUITY - QQQ: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.765228233018688\n",
      "EQUITY - EU: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.822180642397116\n",
      "EQUITY - TAIWAN: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.763129230176001\n",
      "EQUITY - ITALY: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.8223367534535331\n",
      "EQUITY - SWITZERLAND: Best Params: {'class_weight': 'balanced', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7037571560899561\n",
      "EQUITY - SOUTH AFRICA: Best Params: {'class_weight': 'balanced', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7493548383818566\n",
      "FX - USDJPY: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7067177626020931\n",
      "FX - EURUSD: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.727566460462239\n",
      "FX - GBPUSD: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7136533468098823\n",
      "FX - USDCAD: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, Best Negative Log Loss: -0.7093214051063611\n",
      "FX - NZDUSD: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7626465569333601\n",
      "FX - USDMXN: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7590088339359677\n",
      "FX - EURCHF: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.7552769413410634\n",
      "FX - NOKSEK: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7542185899582204\n",
      "FX - EURGBP: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.7532710285724203\n",
      "FX - USDAUD: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Best Negative Log Loss: -0.8016576333966062\n",
      "BONDS - US GOV: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, Best Negative Log Loss: -0.6483589150073751\n",
      "BONDS - CA GOV: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Best Negative Log Loss: -0.7137053451103332\n",
      "BONDS - EURO GOV: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, Best Negative Log Loss: -0.7233222244322834\n",
      "BONDS - EM GOV: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Best Negative Log Loss: -0.6160464583403489\n",
      "BONDS - US IG: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.6686545205326075\n",
      "BONDS - EURO IG: Best Params: {'class_weight': 'balanced', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, Best Negative Log Loss: -0.7541488804599126\n",
      "BONDS - CA IG: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, Best Negative Log Loss: -0.6391967593316388\n",
      "BONDS - US HY: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, Best Negative Log Loss: -0.6836541083065163\n",
      "BONDS - EURO HY: Best Params: {'class_weight': None, 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, Best Negative Log Loss: -0.788407960995138\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store aggregated feature importances and confusion matrices\n",
    "aggregated_feature_importances = {asset_class: [] for asset_class in ASSET_CLASSES}\n",
    "confusion_matrices_rf = {asset_class: [] for asset_class in ASSET_CLASSES}\n",
    "\n",
    "# Process each asset to train models and make predictions\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Initialize dictionaries for predictions and models for each asset class\n",
    "    predictions_rf[asset_class] = {}\n",
    "    models_rf[asset_class] = {}\n",
    "    \n",
    "    # Access data and signals\n",
    "    data_instance = globals()[f\"{asset_class}_data_instance\"]\n",
    "    signals_dict = globals()[f\"{asset_class}_signals_dict\"]\n",
    "    sheet_names = globals()[f\"{asset_class}_sheet_names\"]\n",
    "    \n",
    "    for asset in sheet_names:\n",
    "        try:\n",
    "            # Prepare training data\n",
    "            train_data = data_instance.data[asset].loc[train_start_date:train_end_date]\n",
    "            train_signals = signals_dict[asset].loc[train_start_date:train_end_date]\n",
    "            \n",
    "            # Skip if training data or signals are empty\n",
    "            if train_data.empty or train_signals.empty:\n",
    "                print(f\"Training data or signals for {asset} in {asset_class} is empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Initialize and evaluate RandomForest model\n",
    "            rf_model = RandomForestClassification(train_data, train_signals)\n",
    "            param_grid = {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 5, 10],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2],\n",
    "                'class_weight': [None, 'balanced']\n",
    "            }\n",
    "            best_params, best_score = rf_model.evaluate(n_splits=5, param_grid=param_grid, scoring='neg_log_loss')\n",
    "            print(f\"{asset_class} - {asset}: Best Params: {best_params}, Best Negative Log Loss: {best_score}\")\n",
    "            \n",
    "            # Store the fitted model\n",
    "            models_rf[asset_class][asset] = rf_model\n",
    "            \n",
    "            # Prepare testing data\n",
    "            test_signals_daily = signals_dict[asset].loc[test_start_date:test_end_date]\n",
    "            test_data_daily = data_instance.data[asset].loc[test_start_date:test_end_date]\n",
    "            if test_data_daily.empty or test_signals_daily.empty:\n",
    "                print(f\"Testing data or signals for {asset} in {asset_class} is empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Resample to monthly frequency and align target and features\n",
    "            test_signals_monthly = test_signals_daily.resample('M').last()\n",
    "            test_data_monthly = test_data_daily.resample('M').last()\n",
    "            test_y = test_data_monthly.pct_change().shift(-1).dropna()\n",
    "            test_y_binary = (test_y > 0).astype(int)\n",
    "            test_X = test_signals_monthly.loc[test_y_binary.index].dropna()\n",
    "            test_y_binary = test_y_binary.loc[test_X.index]\n",
    "            test_y = test_y.loc[test_X.index]  # Align actual returns\n",
    "\n",
    "            # Skip if testing data is empty after alignment\n",
    "            if test_X.empty or test_y_binary.empty:\n",
    "                print(f\"No overlapping data between testing features and target for {asset} in {asset_class}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Scale testing features and predict\n",
    "            test_X_scaled = rf_model.scaler.transform(test_X.values)\n",
    "            test_predictions_binary = rf_model.model.predict(test_X_scaled)\n",
    "            \n",
    "            # Compute and store confusion matrix\n",
    "            cm = confusion_matrix(test_y_binary, test_predictions_binary)\n",
    "            confusion_matrices_rf[asset_class].append(cm)\n",
    "            \n",
    "            # Store probability predictions\n",
    "            proba_class_1 = rf_model.model.predict_proba(test_X_scaled)[:, 1]\n",
    "            predictions_rf[asset_class][asset] = pd.DataFrame({\n",
    "                'Actual return': test_y.values.flatten(),\n",
    "                'Proba of going up': proba_class_1\n",
    "            }, index=test_y.index)\n",
    "\n",
    "            # Collect feature importances\n",
    "            aggregated_feature_importances[asset_class].append(rf_model.get_feature_importances()['Importance'].values)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for {asset} in {asset_class}: {e}\")\n",
    "            continue\n",
    "\n",
    "# At this point, 'predictions_rf' dictionary contains predictions for all assets across all asset classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = rf_model.X.columns\n",
    "positions = [2,3]\n",
    "names = []\n",
    "for col_name in feature_names:\n",
    "    name = remove_words_at_positions(col_name, positions)\n",
    "    names.append(name) \n",
    "\n",
    "feature_names = names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average feature importance and Out of Sample Confusion matric for Random Forest model across all asset classes to evaluate model fit and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Feature Importances for COMMOD (Random Forest):\n",
      "                Feature  Mean Importance\n",
      "0     Signal Return 22D         0.195511\n",
      "1     Signal Return 65D         0.177832\n",
      "2        Signal EMA 22D         0.157884\n",
      "3        Signal EMA 65D         0.149158\n",
      "4   Signal MACD 22D 65D         0.141671\n",
      "5  Signal MACD 65D 260D         0.132829\n",
      "6  Signal Bollinger 22D         0.043005\n",
      "7   Signal Breakout 65D         0.002110\n",
      "Plot saved to: Outputs\\COMMOD_Random Forest_importance.png\n",
      "\n",
      "Metrics for COMMOD:\n",
      "Average Precision: 0.55\n",
      "Average Recall: 0.63\n",
      "Average Accuracy: 0.54\n",
      "Average F1 Score: 0.58\n",
      "\n",
      "Average Confusion Matrix for COMMOD:\n",
      "[[0.44560358 0.55439642]\n",
      " [0.37235543 0.62764457]]\n",
      "Plot saved to: Outputs\\COMMOD_average_confusion_matrix.png\n",
      "\n",
      "Average Feature Importances for EQUITY (Random Forest):\n",
      "                Feature  Mean Importance\n",
      "0     Signal Return 22D         0.193892\n",
      "1     Signal Return 65D         0.173885\n",
      "2        Signal EMA 22D         0.161568\n",
      "3        Signal EMA 65D         0.148859\n",
      "4   Signal MACD 22D 65D         0.137387\n",
      "5  Signal MACD 65D 260D         0.128937\n",
      "6  Signal Bollinger 22D         0.037072\n",
      "7   Signal Breakout 65D         0.018400\n",
      "Plot saved to: Outputs\\EQUITY_Random Forest_importance.png\n",
      "\n",
      "Metrics for EQUITY:\n",
      "Average Precision: 0.55\n",
      "Average Recall: 0.62\n",
      "Average Accuracy: 0.49\n",
      "Average F1 Score: 0.58\n",
      "\n",
      "Average Confusion Matrix for EQUITY:\n",
      "[[0.33601071 0.66398929]\n",
      " [0.38548057 0.61451943]]\n",
      "Plot saved to: Outputs\\EQUITY_average_confusion_matrix.png\n",
      "\n",
      "Average Feature Importances for FX (Random Forest):\n",
      "                Feature  Mean Importance\n",
      "0     Signal Return 22D         0.184533\n",
      "1     Signal Return 65D         0.171569\n",
      "2        Signal EMA 22D         0.164732\n",
      "3        Signal EMA 65D         0.149149\n",
      "4   Signal MACD 22D 65D         0.141456\n",
      "5  Signal MACD 65D 260D         0.129974\n",
      "6  Signal Bollinger 22D         0.041758\n",
      "7   Signal Breakout 65D         0.016831\n",
      "Plot saved to: Outputs\\FX_Random Forest_importance.png\n",
      "\n",
      "Metrics for FX:\n",
      "Average Precision: 0.49\n",
      "Average Recall: 0.47\n",
      "Average Accuracy: 0.50\n",
      "Average F1 Score: 0.47\n",
      "\n",
      "Average Confusion Matrix for FX:\n",
      "[[0.52801358 0.47198642]\n",
      " [0.5311943  0.4688057 ]]\n",
      "Plot saved to: Outputs\\FX_average_confusion_matrix.png\n",
      "\n",
      "Average Feature Importances for BONDS (Random Forest):\n",
      "                Feature  Mean Importance\n",
      "0     Signal Return 22D         0.196206\n",
      "1     Signal Return 65D         0.178719\n",
      "2        Signal EMA 22D         0.168660\n",
      "3        Signal EMA 65D         0.154543\n",
      "4   Signal MACD 22D 65D         0.139060\n",
      "5  Signal MACD 65D 260D         0.133240\n",
      "6  Signal Bollinger 22D         0.027489\n",
      "7   Signal Breakout 65D         0.002082\n",
      "Plot saved to: Outputs\\BONDS_Random Forest_importance.png\n",
      "\n",
      "Metrics for BONDS:\n",
      "Average Precision: 0.58\n",
      "Average Recall: 0.80\n",
      "Average Accuracy: 0.56\n",
      "Average F1 Score: 0.67\n",
      "\n",
      "Average Confusion Matrix for BONDS:\n",
      "[[0.22624434 0.77375566]\n",
      " [0.18549747 0.81450253]]\n",
      "Plot saved to: Outputs\\BONDS_average_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# Compute average feature importances per asset class and display\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Plot feature importances for Random Forest\n",
    "    plot_mean_importance(\n",
    "        asset_class,\n",
    "        aggregated_feature_importances[asset_class],\n",
    "        feature_names,\n",
    "        model_name=\"Random Forest\"\n",
    "    )\n",
    "\n",
    "    # Compute and display classification metrics for Random Forest\n",
    "    compute_classification_metrics(\n",
    "        asset_class,\n",
    "        confusion_matrices_rf[asset_class]\n",
    "    )\n",
    "\n",
    "    # Plot average confusion matrix for Random Forest\n",
    "    plot_average_confusion_matrix(\n",
    "        asset_class,\n",
    "        confusion_matrices_rf[asset_class]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each model, we compute cross sectional z-scores of the predictions across all assets in an asset class to measure relative trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              USDJPY    EURUSD    GBPUSD    USDCAD    NZDUSD    USDMXN  \\\n",
      "Date                                                                     \n",
      "2015-01-31 -0.576963 -1.030499  0.551436 -1.514868  1.066373  0.479412   \n",
      "2015-02-28 -0.039668  0.820521 -0.370880 -0.898851 -1.386154  1.250761   \n",
      "2015-03-31 -0.633894 -0.268382  1.686045 -0.885632 -0.879995  0.898807   \n",
      "2015-04-30  0.178183  0.916322  1.343684 -0.588286  0.246514 -0.108786   \n",
      "2015-05-31  1.706249  0.331570 -0.829710 -0.885219  1.742118 -0.666143   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2024-03-31 -0.191432 -0.361858  1.938385 -1.584788 -0.333860  0.657769   \n",
      "2024-04-30  0.811563  0.158720  1.495869  0.071642 -0.708263  1.117229   \n",
      "2024-05-31  0.928008  1.141540 -1.555278  0.421059 -1.293176 -0.306109   \n",
      "2024-06-30  2.092131 -0.037107  0.014444 -1.397179  0.704017  0.788587   \n",
      "2024-07-31  0.295194  0.431514 -0.933498 -0.197737  0.503024  1.390788   \n",
      "\n",
      "              EURCHF    NOKSEK    EURGBP    USDAUD  \n",
      "Date                                                \n",
      "2015-01-31  1.392015  0.185346  0.594145 -1.146396  \n",
      "2015-02-28 -0.242726 -1.051615  1.625832  0.292780  \n",
      "2015-03-31 -0.377590  0.428698  1.238663 -1.206718  \n",
      "2015-04-30  0.054709 -2.059478 -0.902432  0.919570  \n",
      "2015-05-31 -0.314263  0.177417 -0.405802 -0.856217  \n",
      "...              ...       ...       ...       ...  \n",
      "2024-03-31 -0.197976  1.160655 -0.397814 -0.689081  \n",
      "2024-04-30 -1.035112 -1.237291  0.527072 -1.201428  \n",
      "2024-05-31  0.807215 -1.054049  0.840177  0.070614  \n",
      "2024-06-30 -0.835749 -0.066342 -0.791978 -0.470824  \n",
      "2024-07-31 -0.501376  1.105934 -0.056403 -2.037441  \n",
      "\n",
      "[115 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store z-scores for each asset class\n",
    "ridge_zscores = {}\n",
    "linreg_zscores = {}\n",
    "rf_zscores = {}\n",
    "\n",
    "# Loop through each asset class\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Extract predictions for the asset class\n",
    "    ridge_predictions = predictions_ridge[asset_class]  # Ridge predictions\n",
    "    linreg_predictions = predictions_linreg[asset_class]  # Linear Regression predictions\n",
    "    rf_predictions = predictions_rf[asset_class]  # Random Forest predictions\n",
    "    \n",
    "    # Initialize DataFrame to store z-scores for the asset class\n",
    "    ridge_zscores[asset_class] = pd.DataFrame()\n",
    "    linreg_zscores[asset_class] = pd.DataFrame()\n",
    "    rf_zscores[asset_class] = pd.DataFrame()\n",
    "\n",
    "    # Combine predictions from all assets in the asset class into a single DataFrame for Ridge\n",
    "    ridge_combined_df = pd.concat([ridge_predictions[asset]['Predicted Returns'] for asset in asset_class_sheet_names[asset_class]], axis=1)\n",
    "    ridge_combined_df.columns = asset_class_sheet_names[asset_class]  # Set columns as asset names\n",
    "    \n",
    "    # Combine predictions from all assets in the asset class into a single DataFrame for Linear Regression\n",
    "    linreg_combined_df = pd.concat([linreg_predictions[asset]['Predicted Returns'] for asset in asset_class_sheet_names[asset_class]], axis=1)\n",
    "    linreg_combined_df.columns = asset_class_sheet_names[asset_class]  # Set columns as asset names\n",
    "\n",
    "    # Combine predictions from all assets in the asset class into a single DataFrame for RF\n",
    "    rf_combined_df = pd.concat([rf_predictions[asset]['Proba of going up'] for asset in asset_class_sheet_names[asset_class]], axis=1)\n",
    "    rf_combined_df.columns = asset_class_sheet_names[asset_class]  # Set columns as asset names\n",
    "    \n",
    "    # Compute z-scores for Ridge predictions\n",
    "    ridge_zscores[asset_class] = (ridge_combined_df.subtract(ridge_combined_df.mean(axis=1), axis=0)\n",
    "                                  .divide(ridge_combined_df.std(axis=1), axis=0))\n",
    "    \n",
    "    # Compute z-scores for Linear Regression predictions\n",
    "    linreg_zscores[asset_class] = (linreg_combined_df.subtract(linreg_combined_df.mean(axis=1), axis=0)\n",
    "                                   .divide(linreg_combined_df.std(axis=1), axis=0))\n",
    "    \n",
    "    # Compute z-scores for Random Forest predictions\n",
    "    rf_zscores[asset_class] = (rf_combined_df.subtract(rf_combined_df.mean(axis=1), axis=0)\n",
    "                               .divide(rf_combined_df.std(axis=1), axis=0))\n",
    "\n",
    "print(rf_zscores['FX'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We aggregate the z-scores of both models for each asset in each asset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USDJPY</th>\n",
       "      <th>EURUSD</th>\n",
       "      <th>GBPUSD</th>\n",
       "      <th>USDCAD</th>\n",
       "      <th>NZDUSD</th>\n",
       "      <th>USDMXN</th>\n",
       "      <th>EURCHF</th>\n",
       "      <th>NOKSEK</th>\n",
       "      <th>EURGBP</th>\n",
       "      <th>USDAUD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-31</th>\n",
       "      <td>-0.988896</td>\n",
       "      <td>-0.693938</td>\n",
       "      <td>0.385977</td>\n",
       "      <td>-3.612833</td>\n",
       "      <td>1.663186</td>\n",
       "      <td>0.608161</td>\n",
       "      <td>3.221416</td>\n",
       "      <td>0.127118</td>\n",
       "      <td>1.040946</td>\n",
       "      <td>-1.751137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28</th>\n",
       "      <td>-0.983131</td>\n",
       "      <td>1.473926</td>\n",
       "      <td>-0.312209</td>\n",
       "      <td>-1.136207</td>\n",
       "      <td>-0.138064</td>\n",
       "      <td>1.960642</td>\n",
       "      <td>-1.463853</td>\n",
       "      <td>-1.329960</td>\n",
       "      <td>3.043899</td>\n",
       "      <td>-1.115041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>-1.508825</td>\n",
       "      <td>0.819067</td>\n",
       "      <td>1.466136</td>\n",
       "      <td>-2.333819</td>\n",
       "      <td>0.507275</td>\n",
       "      <td>1.593827</td>\n",
       "      <td>-0.180691</td>\n",
       "      <td>0.412381</td>\n",
       "      <td>1.867942</td>\n",
       "      <td>-2.643293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-30</th>\n",
       "      <td>-0.651235</td>\n",
       "      <td>1.769703</td>\n",
       "      <td>1.325230</td>\n",
       "      <td>1.374044</td>\n",
       "      <td>1.108692</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>-0.891374</td>\n",
       "      <td>-2.355512</td>\n",
       "      <td>-1.278853</td>\n",
       "      <td>-0.438212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-31</th>\n",
       "      <td>1.261138</td>\n",
       "      <td>0.976281</td>\n",
       "      <td>-0.498005</td>\n",
       "      <td>-3.049164</td>\n",
       "      <td>3.191713</td>\n",
       "      <td>-0.021557</td>\n",
       "      <td>-0.552216</td>\n",
       "      <td>0.397969</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>-1.738902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>-0.713027</td>\n",
       "      <td>0.431870</td>\n",
       "      <td>2.223252</td>\n",
       "      <td>-2.383574</td>\n",
       "      <td>1.257801</td>\n",
       "      <td>1.211012</td>\n",
       "      <td>-1.893427</td>\n",
       "      <td>1.419393</td>\n",
       "      <td>0.231827</td>\n",
       "      <td>-1.785127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.960598</td>\n",
       "      <td>1.637611</td>\n",
       "      <td>-0.077901</td>\n",
       "      <td>0.695454</td>\n",
       "      <td>1.864951</td>\n",
       "      <td>-2.920834</td>\n",
       "      <td>-1.087600</td>\n",
       "      <td>1.148318</td>\n",
       "      <td>-2.385996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-31</th>\n",
       "      <td>0.363650</td>\n",
       "      <td>1.962081</td>\n",
       "      <td>-1.211515</td>\n",
       "      <td>-1.290555</td>\n",
       "      <td>0.194943</td>\n",
       "      <td>0.347538</td>\n",
       "      <td>0.213676</td>\n",
       "      <td>-0.926968</td>\n",
       "      <td>1.504765</td>\n",
       "      <td>-1.157616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>1.075129</td>\n",
       "      <td>0.632242</td>\n",
       "      <td>0.010197</td>\n",
       "      <td>-2.333378</td>\n",
       "      <td>2.217423</td>\n",
       "      <td>1.995929</td>\n",
       "      <td>-0.953190</td>\n",
       "      <td>-0.118335</td>\n",
       "      <td>-0.404083</td>\n",
       "      <td>-2.121934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>-0.153141</td>\n",
       "      <td>0.935169</td>\n",
       "      <td>-0.759806</td>\n",
       "      <td>-2.364156</td>\n",
       "      <td>1.725066</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>0.134292</td>\n",
       "      <td>1.163695</td>\n",
       "      <td>0.349751</td>\n",
       "      <td>-3.146670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              USDJPY    EURUSD    GBPUSD    USDCAD    NZDUSD    USDMXN  \\\n",
       "Date                                                                     \n",
       "2015-01-31 -0.988896 -0.693938  0.385977 -3.612833  1.663186  0.608161   \n",
       "2015-02-28 -0.983131  1.473926 -0.312209 -1.136207 -0.138064  1.960642   \n",
       "2015-03-31 -1.508825  0.819067  1.466136 -2.333819  0.507275  1.593827   \n",
       "2015-04-30 -0.651235  1.769703  1.325230  1.374044  1.108692  0.037516   \n",
       "2015-05-31  1.261138  0.976281 -0.498005 -3.049164  3.191713 -0.021557   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2024-03-31 -0.713027  0.431870  2.223252 -2.383574  1.257801  1.211012   \n",
       "2024-04-30  0.165400  0.960598  1.637611 -0.077901  0.695454  1.864951   \n",
       "2024-05-31  0.363650  1.962081 -1.211515 -1.290555  0.194943  0.347538   \n",
       "2024-06-30  1.075129  0.632242  0.010197 -2.333378  2.217423  1.995929   \n",
       "2024-07-31 -0.153141  0.935169 -0.759806 -2.364156  1.725066  2.115800   \n",
       "\n",
       "              EURCHF    NOKSEK    EURGBP    USDAUD  \n",
       "Date                                                \n",
       "2015-01-31  3.221416  0.127118  1.040946 -1.751137  \n",
       "2015-02-28 -1.463853 -1.329960  3.043899 -1.115041  \n",
       "2015-03-31 -0.180691  0.412381  1.867942 -2.643293  \n",
       "2015-04-30 -0.891374 -2.355512 -1.278853 -0.438212  \n",
       "2015-05-31 -0.552216  0.397969  0.032744 -1.738902  \n",
       "...              ...       ...       ...       ...  \n",
       "2024-03-31 -1.893427  1.419393  0.231827 -1.785127  \n",
       "2024-04-30 -2.920834 -1.087600  1.148318 -2.385996  \n",
       "2024-05-31  0.213676 -0.926968  1.504765 -1.157616  \n",
       "2024-06-30 -0.953190 -0.118335 -0.404083 -2.121934  \n",
       "2024-07-31  0.134292  1.163695  0.349751 -3.146670  \n",
       "\n",
       "[115 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize dictionary to store the summed z-scores for each asset class\n",
    "summed_zscores = {}\n",
    "\n",
    "# Loop through each asset class\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Extract z-score DataFrames for Ridge and Random Forest\n",
    "    ridge_zscores_df = ridge_zscores[asset_class]\n",
    "    linreg_zscores_df = linreg_zscores[asset_class]\n",
    "    rf_zscores_df = rf_zscores[asset_class]\n",
    "    \n",
    "    # Ensure both DataFrames have the same structure (same columns and index)\n",
    "    ridge_zscores_df = ridge_zscores_df.loc[rf_zscores_df.index, rf_zscores_df.columns]\n",
    "    linreg_zscores_df = linreg_zscores_df.loc[rf_zscores_df.index, rf_zscores_df.columns]\n",
    "    \n",
    "    # Sum the z-scores from both Ridge and Random Forest models\n",
    "    summed_zscores[asset_class] = ridge_zscores_df  + rf_zscores_df\n",
    "\n",
    "summed_zscores['FX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We transform the aggregate z-scores into rankings. Higher z-score gets higher ranking, meaning asset has better return prospects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>UK</th>\n",
       "      <th>EUROSTOXX</th>\n",
       "      <th>JAPAN</th>\n",
       "      <th>HONK KONG</th>\n",
       "      <th>FRANCE</th>\n",
       "      <th>GERMANY</th>\n",
       "      <th>CANADA</th>\n",
       "      <th>RUSSELL2000</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>EU</th>\n",
       "      <th>TAIWAN</th>\n",
       "      <th>ITALY</th>\n",
       "      <th>SWITZERLAND</th>\n",
       "      <th>SOUTH AFRICA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-31</th>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-30</th>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-31</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-31</th>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SPY    UK  EUROSTOXX  JAPAN  HONK KONG  FRANCE  GERMANY  CANADA  \\\n",
       "Date                                                                           \n",
       "2015-01-31  14.0  13.0        3.0    5.0        7.0    10.0      4.0     6.0   \n",
       "2015-02-28   8.0  15.0        4.0    7.0        6.0    14.0      2.0    11.0   \n",
       "2015-03-31  13.0   7.0        3.0    6.0       10.0     9.0      2.0    12.0   \n",
       "2015-04-30  12.0  10.0        6.0    8.0        4.0     9.0     15.0     3.0   \n",
       "2015-05-31  13.0  10.0        8.0    7.0        6.0     9.0      3.0     4.0   \n",
       "...          ...   ...        ...    ...        ...     ...      ...     ...   \n",
       "2024-03-31   5.0  15.0       11.0   13.0        7.0    10.0      4.0     2.0   \n",
       "2024-04-30  11.0   9.0        4.0   15.0        5.0    12.0      7.0     3.0   \n",
       "2024-05-31   7.0  12.0        6.0   13.0        4.0     2.0      5.0     9.0   \n",
       "2024-06-30   3.0   5.0       12.0    6.0        9.0    11.0     13.0     7.0   \n",
       "2024-07-31  13.0   9.0        7.0   12.0       11.0     6.0      3.0     5.0   \n",
       "\n",
       "            RUSSELL2000   QQQ    EU  TAIWAN  ITALY  SWITZERLAND  SOUTH AFRICA  \n",
       "Date                                                                           \n",
       "2015-01-31         12.0  11.0   2.0     9.0    8.0         15.0           1.0  \n",
       "2015-02-28         10.0   9.0  12.0     5.0   13.0          3.0           1.0  \n",
       "2015-03-31          8.0  11.0   4.0     5.0   14.0          1.0          15.0  \n",
       "2015-04-30          7.0  14.0  11.0     5.0   13.0          2.0           1.0  \n",
       "2015-05-31         15.0  14.0   5.0    12.0   11.0          1.0           2.0  \n",
       "...                 ...   ...   ...     ...    ...          ...           ...  \n",
       "2024-03-31          9.0  14.0   6.0     3.0   12.0          8.0           1.0  \n",
       "2024-04-30         13.0   8.0   2.0    10.0   14.0          6.0           1.0  \n",
       "2024-05-31          8.0  14.0   3.0    10.0   11.0         15.0           1.0  \n",
       "2024-06-30          8.0   4.0  14.0     2.0   15.0          1.0          10.0  \n",
       "2024-07-31          1.0  14.0   4.0    10.0    8.0          2.0          15.0  \n",
       "\n",
       "[115 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets_rankings = {}\n",
    "\n",
    "for asset_class in ASSET_CLASSES:\n",
    "\n",
    "    # Get z-scores for each method\n",
    "    summed_zscores_df = summed_zscores[asset_class]\n",
    "\n",
    "    # Rank each asset based on its z-score at each time t\n",
    "    assets_rankings[asset_class] = summed_zscores_df.rank(axis=1, ascending=False)\n",
    "\n",
    "assets_rankings['EQUITY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACRO CLUSTERING - We load the macro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGDP YoY</th>\n",
       "      <th>CPI YoY</th>\n",
       "      <th>UNEM</th>\n",
       "      <th>FED FUNDS</th>\n",
       "      <th>SP500 Vol</th>\n",
       "      <th>RATE 10Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954-07-01</th>\n",
       "      <td>-0.76833</td>\n",
       "      <td>-0.01242</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.078188</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-10-01</th>\n",
       "      <td>2.72862</td>\n",
       "      <td>-0.49585</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.034480</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-01-01</th>\n",
       "      <td>6.17020</td>\n",
       "      <td>-0.59362</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.039658</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-04-01</th>\n",
       "      <td>7.78024</td>\n",
       "      <td>-0.56980</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-07-01</th>\n",
       "      <td>8.01592</td>\n",
       "      <td>-0.23597</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.077818</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>2.29639</td>\n",
       "      <td>8.28869</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.110215</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>1.31633</td>\n",
       "      <td>7.09080</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.140244</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>2.28081</td>\n",
       "      <td>5.74983</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.143436</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>2.82946</td>\n",
       "      <td>4.03157</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.154460</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>3.23631</td>\n",
       "      <td>3.56176</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RGDP YoY  CPI YoY  UNEM  FED FUNDS  SP500 Vol  RATE 10Y\n",
       "Date                                                               \n",
       "1954-07-01  -0.76833 -0.01242   6.0       1.03   0.078188      2.30\n",
       "1954-10-01   2.72862 -0.49585   5.3       0.99   0.034480      2.43\n",
       "1955-01-01   6.17020 -0.59362   4.7       1.34   0.039658      2.61\n",
       "1955-04-01   7.78024 -0.56980   4.4       1.50   0.053287      2.75\n",
       "1955-07-01   8.01592 -0.23597   4.1       1.94   0.077818      2.90\n",
       "...              ...      ...   ...        ...        ...       ...\n",
       "2022-07-01   2.29639  8.28869   3.5       2.19   0.110215      2.90\n",
       "2022-10-01   1.31633  7.09080   3.6       3.65   0.140244      3.98\n",
       "2023-01-01   2.28081  5.74983   3.5       4.52   0.143436      3.53\n",
       "2023-04-01   2.82946  4.03157   3.6       4.99   0.154460      3.46\n",
       "2023-07-01   3.23631  3.56176   3.7       5.26   0.135427      3.90\n",
       "\n",
       "[277 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro = DataReader(MACRO_filepath)\n",
    "econ = macro.load_data([\"ECON\"])\n",
    "price = macro.load_data([\"PRATE\"])\n",
    "\n",
    "econ.index = pd.to_datetime(econ.index)\n",
    "price.index = pd.to_datetime(price.index)\n",
    "econ = econ.loc[econ.index.intersection(price.index)]\n",
    "price = price.loc[econ.index.intersection(price.index)]\n",
    "macro_data = pd.concat([econ, price], axis=1)\n",
    "macro_data.dropna(inplace=True)\n",
    "macro_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the 4 indicators we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGDP YoY</th>\n",
       "      <th>CPI YoY</th>\n",
       "      <th>UNEM</th>\n",
       "      <th>Yield Curve</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954-07-01</th>\n",
       "      <td>-0.76833</td>\n",
       "      <td>-0.01242</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-10-01</th>\n",
       "      <td>2.72862</td>\n",
       "      <td>-0.49585</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-01-01</th>\n",
       "      <td>6.17020</td>\n",
       "      <td>-0.59362</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-04-01</th>\n",
       "      <td>7.78024</td>\n",
       "      <td>-0.56980</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-07-01</th>\n",
       "      <td>8.01592</td>\n",
       "      <td>-0.23597</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>2.29639</td>\n",
       "      <td>8.28869</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>1.31633</td>\n",
       "      <td>7.09080</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>2.28081</td>\n",
       "      <td>5.74983</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>2.82946</td>\n",
       "      <td>4.03157</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>3.23631</td>\n",
       "      <td>3.56176</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RGDP YoY  CPI YoY  UNEM  Yield Curve\n",
       "Date                                            \n",
       "1954-07-01  -0.76833 -0.01242   6.0         1.27\n",
       "1954-10-01   2.72862 -0.49585   5.3         1.44\n",
       "1955-01-01   6.17020 -0.59362   4.7         1.27\n",
       "1955-04-01   7.78024 -0.56980   4.4         1.25\n",
       "1955-07-01   8.01592 -0.23597   4.1         0.96\n",
       "...              ...      ...   ...          ...\n",
       "2022-07-01   2.29639  8.28869   3.5         0.71\n",
       "2022-10-01   1.31633  7.09080   3.6         0.33\n",
       "2023-01-01   2.28081  5.74983   3.5        -0.99\n",
       "2023-04-01   2.82946  4.03157   3.6        -1.53\n",
       "2023-07-01   3.23631  3.56176   3.7        -1.36\n",
       "\n",
       "[277 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_data[\"Yield Curve\"] = macro_data[\"RATE 10Y\"] - macro_data[\"FED FUNDS\"]\n",
    "cols_to_drop = [\"RATE 10Y\", \"FED FUNDS\", \"SP500 Vol\"]\n",
    "macro_data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "macro_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a training, validation and test set for the k-means clustering algortithm + transform the data into time series Z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGDP YoY</th>\n",
       "      <th>CPI YoY</th>\n",
       "      <th>UNEM</th>\n",
       "      <th>Yield Curve</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954-07-01</th>\n",
       "      <td>-1.605925</td>\n",
       "      <td>-1.321707</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.166877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-10-01</th>\n",
       "      <td>-0.178490</td>\n",
       "      <td>-1.490565</td>\n",
       "      <td>-0.428073</td>\n",
       "      <td>0.271155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-01-01</th>\n",
       "      <td>1.226344</td>\n",
       "      <td>-1.524715</td>\n",
       "      <td>-0.803472</td>\n",
       "      <td>0.166877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-04-01</th>\n",
       "      <td>1.883553</td>\n",
       "      <td>-1.516395</td>\n",
       "      <td>-0.991172</td>\n",
       "      <td>0.154609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-07-01</th>\n",
       "      <td>1.979756</td>\n",
       "      <td>-1.399791</td>\n",
       "      <td>-1.178872</td>\n",
       "      <td>-0.023278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>-0.662420</td>\n",
       "      <td>-0.149087</td>\n",
       "      <td>1.636624</td>\n",
       "      <td>0.663733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>-0.215452</td>\n",
       "      <td>-0.329115</td>\n",
       "      <td>1.448924</td>\n",
       "      <td>0.534918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>-0.311267</td>\n",
       "      <td>-0.657937</td>\n",
       "      <td>1.386357</td>\n",
       "      <td>0.553320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "      <td>-0.241723</td>\n",
       "      <td>-0.728864</td>\n",
       "      <td>1.261224</td>\n",
       "      <td>0.240485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01</th>\n",
       "      <td>-0.658840</td>\n",
       "      <td>-0.652470</td>\n",
       "      <td>1.136091</td>\n",
       "      <td>0.363166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RGDP YoY   CPI YoY      UNEM  Yield Curve\n",
       "Date                                                 \n",
       "1954-07-01 -1.605925 -1.321707  0.009893     0.166877\n",
       "1954-10-01 -0.178490 -1.490565 -0.428073     0.271155\n",
       "1955-01-01  1.226344 -1.524715 -0.803472     0.166877\n",
       "1955-04-01  1.883553 -1.516395 -0.991172     0.154609\n",
       "1955-07-01  1.979756 -1.399791 -1.178872    -0.023278\n",
       "...              ...       ...       ...          ...\n",
       "2011-10-01 -0.662420 -0.149087  1.636624     0.663733\n",
       "2012-01-01 -0.215452 -0.329115  1.448924     0.534918\n",
       "2012-04-01 -0.311267 -0.657937  1.386357     0.553320\n",
       "2012-07-01 -0.241723 -0.728864  1.261224     0.240485\n",
       "2012-10-01 -0.658840 -0.652470  1.136091     0.363166\n",
       "\n",
       "[234 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_train_start_date = '1948-01-01'\n",
    "macro_train_end_date = '2012-12-31'\n",
    "macro_val_start_date = '2013-01-01'\n",
    "macro_val_end_date = '2014-12-31'\n",
    "macro_test_start_date = '2015-01-01'\n",
    "macro_test_end_date = '2024-07-01'\n",
    "macro_data_train = macro_data.loc[macro_train_start_date:macro_train_end_date]\n",
    "macro_data_val = macro_data.loc[macro_val_start_date:macro_val_end_date]\n",
    "macro_data_test = macro_data.loc[macro_test_start_date:macro_test_end_date]\n",
    "\n",
    "macro_data_train_z = (macro_data_train - macro_data_train.mean()) / macro_data_train.std()\n",
    "macro_data_train_z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We estimate the k-means algorithm on the training data and store the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeansClustering(macro_data_train_z)\n",
    "kmeans_model = model.k_means_clustering(4)\n",
    "\n",
    "clusters = kmeans_model.labels_\n",
    "centroids = kmeans_model.cluster_centers_\n",
    "macro_data_train_z['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We compute PCAs to be able to visualize the estimated clusters in 2D. Not important for the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the macro data\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(macro_data_train_z.drop(columns='Cluster'))\n",
    "\n",
    "# Project centroids into PCA space\n",
    "centroids_pca = pca.transform(centroids)\n",
    "\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pca_df['Cluster'] = clusters\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in pca_df['Cluster'].unique():\n",
    "    cluster_data = pca_df[pca_df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['PC1'], cluster_data['PC2'], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.scatter(\n",
    "    centroids_pca[:, 0], \n",
    "    centroids_pca[:, 1], \n",
    "    s=250, c='black', marker='X', label='Centroids'\n",
    ")\n",
    "\n",
    "plt.title('K-means Clustering Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "filename = \"kmeans_clustering_pca_visualization.png\"\n",
    "filepath = os.path.join(output_folder, filename)\n",
    "plt.savefig(filepath, bbox_inches='tight')\n",
    "plt.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We calculate the means of our macro indicators to differentiate economic regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGDP YoY</th>\n",
       "      <th>CPI YoY</th>\n",
       "      <th>UNEM</th>\n",
       "      <th>Yield Curve</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.128136</td>\n",
       "      <td>3.444206</td>\n",
       "      <td>6.522857</td>\n",
       "      <td>2.224714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.985715</td>\n",
       "      <td>2.794678</td>\n",
       "      <td>4.674757</td>\n",
       "      <td>0.320583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.169548</td>\n",
       "      <td>3.591809</td>\n",
       "      <td>8.134884</td>\n",
       "      <td>2.138605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.890482</td>\n",
       "      <td>11.063913</td>\n",
       "      <td>6.244444</td>\n",
       "      <td>-2.621667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RGDP YoY    CPI YoY      UNEM  Yield Curve\n",
       "Cluster                                            \n",
       "0        4.128136   3.444206  6.522857     2.224714\n",
       "1        3.985715   2.794678  4.674757     0.320583\n",
       "2        0.169548   3.591809  8.134884     2.138605\n",
       "3        1.890482  11.063913  6.244444    -2.621667"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_data_train['Cluster'] = clusters\n",
    "cluster_means = macro_data_train.groupby('Cluster').mean()\n",
    "cluster_means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that Cluster 0 is a high growth and upward sloping yield curve environment. \n",
    "#### Cluster 1 is decent growth, but flat yield curve. \n",
    "#### Cluster 2 is recessions. \n",
    "#### Cluster 3 is High inflation and iverted yield curve environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on these 4 disctinct economic regimes, we establish discretionary asset class deviations based on expected returns founded on financial and economic theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the asset classes\n",
    "ASSET_CLASSES = ['EQUITY', 'BONDS', 'FX', 'COMMOD']\n",
    "\n",
    "# Define the base equal weights\n",
    "base_weights = {asset_class: 1 / len(ASSET_CLASSES) for asset_class in ASSET_CLASSES}\n",
    "\n",
    "# Define the adjustment rules based on clusters\n",
    "cluster_adjustments = {\n",
    "    0: {'EQUITY': +0.10, 'BONDS': -0.10, 'FX': 0.00, 'COMMOD': 0.00},\n",
    "    1: {'EQUITY': +0.05, 'BONDS': -0.05, 'FX': +0.05, 'COMMOD': -0.05},\n",
    "    2: {'EQUITY': -0.10, 'BONDS': +0.10, 'FX': -0.05, 'COMMOD': +0.05},\n",
    "    3: {'EQUITY': +0.05, 'BONDS': -0.10, 'FX': -0.05, 'COMMOD': +0.10},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now predict clusters in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the macro data in the test set using the training mean and std\n",
    "macro_data_train = macro_data_train.drop(columns='Cluster')\n",
    "# Standardize the macro data in the test set using the training mean and std\n",
    "macro_data_test_z = (macro_data_test - macro_data_train.mean()) / macro_data_train.std()\n",
    "\n",
    "# Predict clusters on the test set\n",
    "test_clusters = kmeans_model.predict(macro_data_test_z)\n",
    "macro_data_test_z['Cluster'] = test_clusters\n",
    "\n",
    "# Assign the cluster labels to the dates in the test set\n",
    "cluster_series = pd.Series(test_clusters, index=macro_data_test_z.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on predicted clusters in the test set, we compute asset class weights over the whole backtesting period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store adjusted weights over time\n",
    "dates = macro_data_test_z.index\n",
    "adjusted_weights_df = pd.DataFrame(index=dates, columns=ASSET_CLASSES)\n",
    "\n",
    "for date in dates:\n",
    "    cluster = cluster_series.loc[date]\n",
    "    adjustments = cluster_adjustments.get(cluster, {asset_class: 0.0 for asset_class in ASSET_CLASSES})\n",
    "    \n",
    "    # Adjust the base weights\n",
    "    adjusted_weights = {}\n",
    "    for asset_class in ASSET_CLASSES:\n",
    "        adjusted_weight = base_weights[asset_class] + adjustments[asset_class]\n",
    "        adjusted_weights[asset_class] = adjusted_weight\n",
    "    \n",
    "    # Normalize the weights to ensure they sum to 1\n",
    "    total_weight = sum(adjusted_weights.values())\n",
    "    normalized_weights = {asset_class: weight / total_weight for asset_class, weight in adjusted_weights.items()}\n",
    "    \n",
    "    # Store the normalized weights\n",
    "    adjusted_weights_df.loc[date] = normalized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EQUITY</th>\n",
       "      <th>BONDS</th>\n",
       "      <th>FX</th>\n",
       "      <th>COMMOD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EQUITY BONDS    FX COMMOD\n",
       "Date                                \n",
       "2015-01-01   0.35  0.15  0.25   0.25\n",
       "2015-04-01    0.3   0.2   0.3    0.2\n",
       "2015-07-01   0.35  0.15  0.25   0.25\n",
       "2015-10-01    0.3   0.2   0.3    0.2\n",
       "2016-01-01    0.3   0.2   0.3    0.2\n",
       "2016-04-01    0.3   0.2   0.3    0.2\n",
       "2016-07-01    0.3   0.2   0.3    0.2\n",
       "2016-10-01    0.3   0.2   0.3    0.2\n",
       "2017-01-01    0.3   0.2   0.3    0.2\n",
       "2017-04-01    0.3   0.2   0.3    0.2\n",
       "2017-07-01    0.3   0.2   0.3    0.2\n",
       "2017-10-01    0.3   0.2   0.3    0.2\n",
       "2018-01-01    0.3   0.2   0.3    0.2\n",
       "2018-04-01    0.3   0.2   0.3    0.2\n",
       "2018-07-01    0.3   0.2   0.3    0.2\n",
       "2018-10-01    0.3   0.2   0.3    0.2\n",
       "2019-01-01    0.3   0.2   0.3    0.2\n",
       "2019-04-01    0.3   0.2   0.3    0.2\n",
       "2019-07-01    0.3   0.2   0.3    0.2\n",
       "2019-10-01    0.3   0.2   0.3    0.2\n",
       "2020-01-01    0.3   0.2   0.3    0.2\n",
       "2020-04-01   0.15  0.35   0.2    0.3\n",
       "2020-07-01   0.15  0.35   0.2    0.3\n",
       "2020-10-01   0.15  0.35   0.2    0.3\n",
       "2021-01-01   0.35  0.15  0.25   0.25\n",
       "2021-04-01   0.35  0.15  0.25   0.25\n",
       "2021-07-01    0.3   0.2   0.3    0.2\n",
       "2021-10-01    0.3   0.2   0.3    0.2\n",
       "2022-01-01    0.3   0.2   0.3    0.2\n",
       "2022-04-01    0.3   0.2   0.3    0.2\n",
       "2022-07-01    0.3   0.2   0.3    0.2\n",
       "2022-10-01    0.3   0.2   0.3    0.2\n",
       "2023-01-01    0.3   0.2   0.3    0.2\n",
       "2023-04-01    0.3   0.2   0.3    0.2\n",
       "2023-07-01    0.3   0.2   0.3    0.2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKTEST\n",
    "### We now compute the overall backtest of the strategy over the testing set.\n",
    "#### We compute 3 strategies. The first is our overall strategy with the macro deviations over the asset classes and the ranking methodology inside the asset classes. The second is the strategy without the macro overlay, which means we simply use equal weights over the asset class portfolios. The final one is the benchmark, which is not only equal weight over the asset classes but also within the assets in each class. This means the benchmark doesnt use the ranks from our models nor the macro deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize Asset Rankings\n",
    "assets_rankings = {}\n",
    "\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Get summed z-scores DataFrame for the asset class\n",
    "    summed_zscores_df = summed_zscores[asset_class]\n",
    "    \n",
    "    # Rank each asset based on its summed z-score at each time t\n",
    "    assets_rankings[asset_class] = summed_zscores_df.rank(axis=1, ascending=False)\n",
    "\n",
    "# Initialize dictionaries to store cumulative returns, individual returns, and weights\n",
    "strategy_cum_returns = {}\n",
    "asset_class_returns = {}\n",
    "asset_weights = {}\n",
    "\n",
    "# Define testing date range\n",
    "test_start_date = macro_test_start_date\n",
    "test_end_date = macro_test_end_date\n",
    "\n",
    "# Step 2: Calculate strategy-based weights for each asset class and compute returns\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    data_instance = globals()[f\"{asset_class}_data_instance\"]\n",
    "    test_data_daily = data_instance.data.loc[test_start_date:test_end_date]\n",
    "    \n",
    "    # Resample to monthly frequency and calculate monthly returns\n",
    "    test_data_monthly = test_data_daily.resample('M').last()\n",
    "    test_data_monthly = test_data_monthly.pct_change().shift(-1).dropna()\n",
    "    \n",
    "    assets_rankings_df = assets_rankings[asset_class]\n",
    "    \n",
    "    # Ensure indices match\n",
    "    common_index = test_data_monthly.index.intersection(assets_rankings_df.index)\n",
    "    test_data_monthly = test_data_monthly.loc[common_index]\n",
    "    assets_rankings_df = assets_rankings_df.loc[common_index]\n",
    "    \n",
    "    # Initialize DataFrame to store strategy weights\n",
    "    strategy_weights = pd.DataFrame(index=assets_rankings_df.index, columns=assets_rankings_df.columns)\n",
    "    \n",
    "    # Calculate strategy weights based on inverse ranks\n",
    "    for i in range(len(assets_rankings_df)):\n",
    "        # Get the ranks of assets for the current date\n",
    "        ranked_assets = assets_rankings_df.iloc[i]\n",
    "        \n",
    "        # Calculate inverse rank weights (higher rank gets higher weight)\n",
    "        inverse_ranks = 1 / ranked_assets\n",
    "        \n",
    "        # Normalize the weights so that they sum up to 1\n",
    "        normalized_weights = inverse_ranks / inverse_ranks.sum()\n",
    "        \n",
    "        # Assign weights to the DataFrame for the current row\n",
    "        strategy_weights.iloc[i] = normalized_weights.values\n",
    "    \n",
    "    # Store the asset weights for this asset class\n",
    "    asset_weights[asset_class] = strategy_weights\n",
    "    \n",
    "    # Calculate monthly portfolio returns using strategy weights\n",
    "    monthly_returns = (test_data_monthly * strategy_weights).sum(axis=1)\n",
    "    asset_class_returns[asset_class] = monthly_returns\n",
    "    \n",
    "    # Calculate cumulative returns for the strategy-based portfolio\n",
    "    strategy_cum_returns[asset_class] = (1 + monthly_returns).cumprod()\n",
    "\n",
    "# Step 3: Compute asset class volatilities using covariance matrices and inverse ranking weights\n",
    "asset_class_vols = {}\n",
    "\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    # Get the covariance matrix for the asset class\n",
    "    cov_matrix = cov_matrices[asset_class]\n",
    "    \n",
    "    # Get the strategy weights for the asset class\n",
    "    strategy_weights = asset_weights[asset_class]\n",
    "    \n",
    "    # Ensure the covariance matrix and weights have matching columns\n",
    "    cov_matrix = cov_matrix.loc[strategy_weights.columns, strategy_weights.columns]\n",
    "    \n",
    "    # Compute average weights over the period\n",
    "    avg_weights = strategy_weights.iloc[0]\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    weights = avg_weights.values.astype(float)\n",
    "    \n",
    "    # Compute portfolio variance: w.T * Cov * w\n",
    "    portfolio_var = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    \n",
    "    # Take square root to get volatility\n",
    "    portfolio_vol = np.sqrt(portfolio_var)\n",
    "    \n",
    "    # Store the volatility for the asset class\n",
    "    asset_class_vols[asset_class] = portfolio_vol\n",
    "\n",
    "# Step 4: Compute risk parity weights for asset classes based on calculated volatilities\n",
    "inverse_vols = {asset_class: 1 / vol for asset_class, vol in asset_class_vols.items()}\n",
    "total_inverse_vols = sum(inverse_vols.values())\n",
    "risk_parity_weights = {asset_class: inverse_vol / total_inverse_vols for asset_class, inverse_vol in inverse_vols.items()}\n",
    "\n",
    "# Step 5: Calculate global strategy portfolio returns using risk parity weights\n",
    "global_portfolio_returns = pd.Series(0, index=next(iter(asset_class_returns.values())).index)\n",
    "adjusted_weights_df.index = adjusted_weights_df.index.to_period('M').to_timestamp('M')\n",
    "\n",
    "global_portfolio_returns_cluster = pd.Series(0, index=next(iter(asset_class_returns.values())).index)\n",
    "\n",
    "for asset_class, returns in asset_class_returns.items():\n",
    "    returns_rp = returns.reindex(global_portfolio_returns.index).fillna(0)\n",
    "    global_portfolio_returns += risk_parity_weights[asset_class] * returns_rp\n",
    "    \n",
    "    weights_cluster = adjusted_weights_df[asset_class].astype(float)\n",
    "    weights_cluster = weights_cluster.reindex(returns.index).fillna(method='ffill')\n",
    "    \n",
    "    common_index = weights_cluster.index.intersection(returns.index)\n",
    "    weights_cluster = weights_cluster.loc[common_index]\n",
    "    returns_cluster = returns.loc[common_index]\n",
    "    \n",
    "    weighted_returns = weights_cluster * returns_cluster\n",
    "    global_portfolio_returns_cluster = global_portfolio_returns_cluster.add(weighted_returns, fill_value=0)\n",
    "\n",
    "global_strategy_cum_returns = (1 + global_portfolio_returns).cumprod()\n",
    "global_strategy_cum_returns_cluster = (1 + global_portfolio_returns_cluster).cumprod()\n",
    "\n",
    "# -------------------------\n",
    "# Benchmark Calculation\n",
    "# -------------------------\n",
    "\n",
    "equal_weight_returns_dict = {}\n",
    "equal_weight_cum_returns = {}\n",
    "equal_weight_asset_class_vols = {}\n",
    "\n",
    "for asset_class in ASSET_CLASSES:\n",
    "    data_instance = globals()[f\"{asset_class}_data_instance\"]\n",
    "    test_data_daily = data_instance.data.loc[test_start_date:test_end_date]\n",
    "    test_data_monthly = test_data_daily.resample('M').last()\n",
    "    test_data_monthly = test_data_monthly.pct_change().shift(-1).dropna()\n",
    "    \n",
    "    num_assets = len(test_data_monthly.columns)\n",
    "    equal_weights = np.ones(num_assets) / num_assets\n",
    "    \n",
    "    test_data_monthly = test_data_monthly.loc[test_data_monthly.index.intersection(global_portfolio_returns.index)]\n",
    "    \n",
    "    equal_weight_returns = test_data_monthly.dot(equal_weights)\n",
    "    equal_weight_returns_dict[asset_class] = equal_weight_returns\n",
    "    \n",
    "    cum_returns = (1 + equal_weight_returns).cumprod()\n",
    "    equal_weight_cum_returns[asset_class] = cum_returns\n",
    "    \n",
    "    cov_matrix = cov_matrices[asset_class]\n",
    "    cov_matrix = cov_matrix.loc[test_data_monthly.columns, test_data_monthly.columns]\n",
    "    \n",
    "    portfolio_var = np.dot(equal_weights.T, np.dot(cov_matrix, equal_weights))\n",
    "    portfolio_vol = np.sqrt(portfolio_var)\n",
    "    equal_weight_asset_class_vols[asset_class] = portfolio_vol\n",
    "\n",
    "inverse_vols_benchmark = {asset_class: 1 / vol if vol != 0 else 0 for asset_class, vol in equal_weight_asset_class_vols.items()}\n",
    "total_inverse_vols_benchmark = sum(inverse_vols_benchmark.values())\n",
    "risk_parity_weights_benchmark = {asset_class: inverse_vol / total_inverse_vols_benchmark if total_inverse_vols_benchmark != 0 else 1 / len(ASSET_CLASSES) for asset_class, inverse_vol in inverse_vols_benchmark.items()}\n",
    "\n",
    "benchmark_portfolio_returns = pd.Series(0, index=global_portfolio_returns.index)\n",
    "\n",
    "for asset_class, returns in equal_weight_returns_dict.items():\n",
    "    returns_benchmark = returns.reindex(benchmark_portfolio_returns.index).fillna(0)\n",
    "    benchmark_portfolio_returns += risk_parity_weights_benchmark[asset_class] * returns_benchmark\n",
    "\n",
    "benchmark_strategy_cum_returns = (1 + benchmark_portfolio_returns).cumprod()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Plotting\n",
    "# -------------------------\n",
    "\n",
    "# Ensure all cumulative return series have the same index\n",
    "common_index = global_strategy_cum_returns.index.intersection(global_strategy_cum_returns_cluster.index).intersection(benchmark_strategy_cum_returns.index)\n",
    "global_strategy_cum_returns = global_strategy_cum_returns.loc[common_index]\n",
    "global_strategy_cum_returns_cluster = global_strategy_cum_returns_cluster.loc[common_index]\n",
    "benchmark_strategy_cum_returns = benchmark_strategy_cum_returns.loc[common_index]\n",
    "\n",
    "# Plot 1: Individual Asset Classes' Cumulative Returns (Equal Weight)\n",
    "plt.figure(figsize=(14, 7))\n",
    "for asset_class, cum_returns in equal_weight_cum_returns.items():\n",
    "    plt.plot(cum_returns.index, cum_returns, label=f'{asset_class} Equal Weight', linestyle='--')\n",
    "\n",
    "plt.title('Cumulative Returns of Individual Asset Classes (Equal Weight)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "filename = \"individual_asset_classes_equal_weight.png\"\n",
    "filepath = os.path.join(output_folder, filename)\n",
    "plt.savefig(filepath, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Portfolio Performance Comparison\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(global_strategy_cum_returns, label='Strat sans macro', linewidth=2, linestyle=':')\n",
    "plt.plot(global_strategy_cum_returns_cluster, label='Macro Clustering Portfolio', linewidth=2)\n",
    "plt.plot(benchmark_strategy_cum_returns, label='Benchmark Portfolio', linewidth=2, linestyle='-.')\n",
    "plt.title('Portfolio Performance Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "filename = \"portfolio_performance_comparison.png\"\n",
    "filepath = os.path.join(output_folder, filename)\n",
    "plt.savefig(filepath, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Return Differences Between Portfolios\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Calculate return differences\n",
    "return_diff_global_benchmark = global_strategy_cum_returns - benchmark_strategy_cum_returns\n",
    "return_diff_cluster_benchmark = global_strategy_cum_returns_cluster - benchmark_strategy_cum_returns\n",
    "return_diff_cluster_global = global_strategy_cum_returns_cluster - global_strategy_cum_returns\n",
    "\n",
    "# Plot the return differences\n",
    "plt.plot(return_diff_global_benchmark, label='Strat sans macro - Benchmark', linewidth=2)\n",
    "plt.plot(return_diff_cluster_benchmark, label='Macro Clustering - Benchmark', linewidth=2)\n",
    "plt.plot(return_diff_cluster_global, label='Macro Clustering - Strat sans macro', linewidth=2)\n",
    "plt.title('Return Differences Between Portfolios')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return Difference')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "filename = \"return_differences_between_portfolios.png\"\n",
    "filepath = os.path.join(output_folder, filename)\n",
    "plt.savefig(filepath, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We compute descriptive statistics over the strategies on the backtest returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <td>0.163378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>-0.136201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative Return</th>\n",
       "      <td>0.528875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Return</th>\n",
       "      <td>0.048409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Volatility</th>\n",
       "      <td>0.085535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value\n",
       "Sharpe Ratio       0.163378\n",
       "Max Drawdown      -0.136201\n",
       "Cumulative Return  0.528875\n",
       "Mean Return        0.048409\n",
       "Mean Volatility    0.085535"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = DescriptiveStatistics(global_portfolio_returns_cluster)\n",
    "stats.performance_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <td>0.148663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>-0.096435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative Return</th>\n",
       "      <td>0.235831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Return</th>\n",
       "      <td>0.023329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Volatility</th>\n",
       "      <td>0.045301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value\n",
       "Sharpe Ratio       0.148663\n",
       "Max Drawdown      -0.096435\n",
       "Cumulative Return  0.235831\n",
       "Mean Return        0.023329\n",
       "Mean Volatility    0.045301"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = DescriptiveStatistics(global_portfolio_returns)\n",
    "stats.performance_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <td>0.180234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>-0.080398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative Return</th>\n",
       "      <td>0.187194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Return</th>\n",
       "      <td>0.018513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Volatility</th>\n",
       "      <td>0.029651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value\n",
       "Sharpe Ratio       0.180234\n",
       "Max Drawdown      -0.080398\n",
       "Cumulative Return  0.187194\n",
       "Mean Return        0.018513\n",
       "Mean Volatility    0.029651"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = DescriptiveStatistics(benchmark_portfolio_returns)\n",
    "stats.performance_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
